pathToResults <- getwd()# paste0(getwd(), "/DEMO")

user <- Sys.getenv("DB_USERNAME") #TODO
pw <- Sys.getenv("DB_PASSWORD") #TODO
server <- stringr::str_c(Sys.getenv("DB_HOST"), "/", Sys.getenv("DB_NAME")) #TODO
port <- Sys.getenv("DB_PORT") #TODO

cdmSchema <-
  Sys.getenv("OHDSI_CDM") #TODO # Schema which contains the OHDSI Common Data Model
cdmVocabSchema <-
  Sys.getenv("OHDSI_VOCAB") #TODO # Schema which contains the OHDSI Common Data Model vocabulary tables.
cdmResultsSchema <-
  Sys.getenv("OHDSI_RESULTS") #TODO # Schema which will contain the final results
writeSchema <-
  Sys.getenv("OHDSI_WRITE") #TODO # Schema for temporary tables, will be deleted


db = DBI::dbConnect(
  RPostgres::Postgres(),
  dbname = Sys.getenv("DB_NAME"),
  host = Sys.getenv("DB_HOST"),
  user = Sys.getenv("DB_USERNAME"),
  password = Sys.getenv("DB_PASSWORD"),
  port  = port
)

cdm <- CDMConnector::cdmFromCon(
  con = db,
  cdmSchema = cdmSchema,
  achillesSchema = cdmResultsSchema,
  writeSchema = writeSchema,
)

library(dplyr)

targetCohort = test$data_initial %>% filter(COHORT_DEFINITION_ID == "target")
colnames(targetCohort) = tolower(colnames(targetCohort))
#targetCohort = cohortFromJSON(pathToJSON = getwd(), cdm = cdm)
controlCohort = test$data_initial %>% filter(COHORT_DEFINITION_ID == "control")
colnames(controlCohort) = tolower(colnames(controlCohort))
#controlCohort = createControlCohortMatching(cdm = cdm, targetTable = targetCohort,ratio = 4)

data = CohortContrast::CohortContrast(
  cdm,
  targetTable = targetCohort,
  controlTable = controlCohort,
  pathToResults = getwd(),
  domainsIncluded = c(
    "Drug",
    "Condition",
    "Measurement",
    "Observation",
    "Procedure",
    "Visit",
    "Visit detail"
  ),
  prevalenceCutOff = FALSE,
  getAllAbstractions = FALSE,
  maximumAbstractionLevel = 5,
  topK = FALSE, # Number of features to export
  presenceFilter = 0.2, # 0-1, percentage of people who must have the chosen feature present
  complementaryMappingTable = FALSE, # A table for manual concept_id and concept_name mapping (merge)
  lookbackDays = FALSE,
  getSourceData = FALSE,
  runZTests = TRUE,
  runLogitTests = TRUE,
  runKSTests = TRUE,
  createOutputFiles = TRUE,
  safeRun = FALSE,
  complName = 'Malignant_neoplasm_of_breast')

CohortContrast::runCohortContrastGUI(
  pathToResults = paste0(getwd(), "/DEMO")
)

# Temo start 
library(dplyr)
library(tidyr)
# Cohort2Trajectory
mapped_data <- readRDS("~/UT/R-packages/Develop/DEMO_FAST/Malignant_neoplasm_of_breast_1_year_after_vs_prior_mapped.rds")
mapped_data <- createC2TInput(mapped_data, cdm)
mapped_trajectories = C2TCaller(mapped_data, pathToResults = pathToResults)

# Apriori?
#mapped_data <- readRDS("~/UT/R-packages/Develop/DEMO_FAST/Malignant_neoplasm_of_breast_1_year_after_vs_prior_mapped.rds")
data = mapped_data$trajectoryDataList$trajectoryData %>% select(COHORT_DEFINITION_ID, SUBJECT_ID) %>% distinct()



library(arules)


data_apriori = mapped_data$data_patients %>% filter(COHORT_DEFINITION_ID == "target", ABSTRACTION_LEVEL == -1) %>% select(PERSON_ID, CONCEPT_NAME) %>% distinct()
transactions <- as(split(data_apriori$CONCEPT_NAME, data_apriori$PERSON_ID), "transactions")
inspect(transactions)


# Finding frequent itemsets
#frequent_itemsets <- apriori(transactions, parameter = list(supp = 0.5, target = "frequent itemsets")) # Create a view for the supports and the change slider?
frequent_itemsets <- apriori(transactions, parameter = list(support = 0.5, confidence = 0.9, minlen = 2,target = "rules"))

# Display the frequent itemsets
inspect(head(sort(frequent_itemsets, by = "lift"), 40))


library(arulesViz)
plot(frequent_itemsets, method = "graph", control = list(type = "items"), measure = "confidence")

rules <- apriori(transactions, parameter = list(supp = 0.6, conf = 0.8, target = "rules"))

a = inspect(sort(rules, by = "lift"))



# Median times for subsets
data_times = mapped_trajectories %>% select(SUBJECT_ID, STATE_LABEL, TIME_IN_COHORT) %>% filter(STATE_LABEL != "START", STATE_LABEL != "EXIT")
data_times

# Calculate the median time for each STATE_LABEL across all subjects
# Step 1: Filter for first occurrences
first_occurrences <- data_times %>%
  arrange(SUBJECT_ID, TIME_IN_COHORT) %>%
  group_by(SUBJECT_ID, STATE_LABEL) %>%
  slice(1) %>%
  ungroup()

# Step 2: Calculate the global median for each STATE_LABEL
global_median_times <- first_occurrences %>%
  group_by(STATE_LABEL) %>%
  summarise(Global_Median_Time = median(TIME_IN_COHORT), .groups = 'drop') %>%
  mutate(Global_Median_Time_days = Global_Median_Time * 365)

print(global_median_times)


# Step 3: Calculate medians for subsets of state labels per subject
# Create a wide format dataset where each row is a subject and columns are states
wide_data <- first_occurrences %>%
  pivot_wider(names_from = STATE_LABEL, values_from = TIME_IN_COHORT)

subset_medians <- list()

# Loop through each subject's data
for (i in 1:nrow(wide_data)) {
  # Find non-NA values for the subject
  present_states <- colnames(wide_data)[which(!is.na(wide_data[i, -1])) + 1]

  # Generate all non-empty subsets of present states
  if (length(present_states) > 0) {
    for (j in 1:length(present_states)) {
      # Safely generate combinations only if there are enough states
      if (j <= length(present_states)) {
        combinations <- combn(present_states, j, simplify = FALSE)

        for (combo in combinations) {
          combo_name <- toString(sort(combo))
          max_time <- max(wide_data[i, combo], na.rm = TRUE)

          # Append to the list
          subset_medians[[length(subset_medians) + 1]] <- data.frame(
            Subset = combo_name,
            Max_Time = max_time
          )
        }
      }
    }
  }
}

# Convert the list of data frames into a single data frame
all_subsets <- do.call(rbind, subset_medians)

# Calculate global median times for each subset
global_subset_medians <- all_subsets %>%
  group_by(Subset) %>%
  summarise(Global_Median_Time = median(Max_Time), .groups = 'drop') %>%
  mutate(Global_Median_Time_days = Global_Median_Time * 365) %>% arrange(desc(Global_Median_Time_days))

print(global_subset_medians)

global_subset_medians %>% filter(Subset == "Chemotherapy, Hormone_therapy, Radiotherapy")

